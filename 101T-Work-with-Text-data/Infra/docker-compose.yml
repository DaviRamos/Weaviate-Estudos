name: ProjetoWeaviateAcademy

# É necessário baixar este modelo sno container do ollama
# ollama pull nomic-embed-text
# ollama pull llama3.2
# ollama pull snowflake-arctic-embed

networks:
  local-network:
    external: true

volumes:
  ollama-data:
  weaviate_data:

services:
  weaviate:
    command: ["--host", "0.0.0.0", "--port", "8080","--scheme", "http"]  
    image: cr.weaviate.io/semitechnologies/weaviate:1.32.3
    container_name: weaviate-container
    networks:
      - local-network
    ports:
    - "8080:8080"  # REST calls
    - "50051:50051"  # gRPC calls
    volumes:
    - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      OLLAMA_URL: http://ollama-container:11434
      OLLAMA_MODEL: llama3.2
      OLLAMA_EMBED_MODEL: nomic-embed-text:latest
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      ENABLE_API_BASED_MODULES: 'true'
      ENABLE_MODULES: 'text2vec-ollama,generative-ollama'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-ollama'
      CLUSTER_HOSTNAME: 'node1'   
      
  ollama:
    image: ollama/ollama
    container_name: ollama-container
#    command: ["ollama", "pull", "llama2"]
    networks:
      - local-network
    volumes:
      - ollama-data:/root/.ollama    
    ports:
      - "11434:11434"
    pull_policy: always
    tty: true
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 2G
        reservations:
          cpus: '0.25'  
          devices:
            - driver: ${OLLAMA_GPU_DRIVER-nvidia}
              count: ${OLLAMA_GPU_COUNT-1}
              capabilities:
                - gpu  