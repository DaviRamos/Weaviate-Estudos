name: ProjetoWeaviateAcademy

# É necessário baixar este modelo sno container do ollama
# ollama pull nomic-embed-text
# ollama pull llama3.2
# ollama pull snowflake-arctic-embed

networks:
  local-network:
    external: true

volumes:  
  weaviate_data:
  ollama-data:

services:
  weaviate:
    command: ["--host", "0.0.0.0", "--port", "8080","--scheme", "http"]  
    image: cr.weaviate.io/semitechnologies/weaviate:1.32.4
    container_name: weaviate1.32.4-container
    networks:
      - local-network
    ports:
    - "8080:8080"  # REST calls
    - "50051:50051"  # gRPC calls
    volumes:
    - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      CLIP_INFERENCE_API: 'http://multi2vec-clip:8080'
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      ENABLE_MODULES: 'multi2vec-clip,text2vec-ollama,generative-ollama'      
      ENABLE_API_BASED_MODULES: 'true'
      CLUSTER_HOSTNAME: 'node1'
      
  multi2vec-clip:
    image: cr.weaviate.io/semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32-multilingual-v1
    environment:
      ENABLE_CUDA: '0'
    networks:
      - local-network
   
  ollama:
    image: ollama/ollama
    container_name: ollama-container
#    command: ["ollama", "pull", "llama2"]
    networks:
      - local-network
    volumes:
      - ollama-data:/root/.ollama    
    ports:
      - "11434:11434"
    pull_policy: always
    tty: true
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 2G
        reservations:
          cpus: '0.25'  
          devices:
            - driver: ${OLLAMA_GPU_DRIVER-nvidia}
              count: ${OLLAMA_GPU_COUNT-1}
              capabilities:
                - gpu  